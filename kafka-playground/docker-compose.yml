version: '3.7'

# Following reference
# Link: https://github.com/confluentinc/cp-docker-images/blob/5.3.3-post/examples/kafka-cluster/docker-compose.yml

services:
  # ============================================================= zookeeper cluster ========================================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
  # ============================================================= kafka cluster ========================================================================
  kafka:
    image: confluentinc/cp-kafka:latest
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # ============================================================= kafka-kafdrop ========================================================================
  kafka-kafdrop:
    image: obsidiandynamics/kafdrop
    hostname: kafka-kafdrop
    container_name: kafka-kafdrop
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
      JVM_OPTS: "-XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
    depends_on:
      - kafka
  # ============================================================= Kafka Schema Registry ========================================================================
  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:latest
    hostname: kafka-schema-registry
    container_name: kafka-schema-registry
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092
      SCHEMA_REGISTRY_HOST_NAME: kafka-schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    depends_on:
      - kafka

  # 개요: kafka-schema-registry 이걸 좀 더 쉽게 다루기 위해 존재하는 web ui 툴
  kafka-schema-registry-ui:
    image: landoop/schema-registry-ui:latest
    hostname: kafka-schema-registry-ui
    container_name: kafka-schema-registry-ui
    ports:
      - "8000:8000"
    environment:
      SCHEMAREGISTRY_URL: http://kafka-schema-registry:8081
      PROXY: "true"
    depends_on:
      - kafka-schema-registry

  # ============================================================= Kafka Connector ========================================================================
  kafka-connect-ui:
    image: landoop/kafka-connect-ui:latest
    hostname: kafka-connect-ui
    container_name: kafka-connect-ui
    ports:
      - "8001:8000"
    environment:
      CONNECT_URL: "http://kafka-connect-datagen:8083"
      PROXY: "true"
    depends_on:
      - kafka-connect-datagen

  kafka-connect-datagen:
    image: cnfldemos/kafka-connect-datagen:0.3.2-5.5.0
    hostname: kafka-connect-datagen
    container_name: kafka-connect-datagen
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_ZOOKEEPER_CONNECT: zookeeper:2181
      CONNECT_GROUP_ID: compose-connect-group

      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: connect

      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1

      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1

      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1

      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://kafka-schema-registry:8081

      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter

      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/etc/kafka-connect/jars
      CONNECT_LOG4J_LOGGERS: org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR
    volumes:
      - ./kafka-connect:/usr/share/confluent-hub-components/confluentinc-kafka-connect-datagen/etc/custom
    depends_on:
      - kafka-schema-registry
  
  
  # ================================ Elastic Stack ================================
  elasticsearch:
    image: elasticsearch:7.8.1
    hostname: elasticsearch
    container_name: elasticsearch
    ports:
      - 9200:9200
    environment:
      - cluster.name=cluster
      - network.host=0.0.0.0
      - node.name=elasitcsearch-standalone
      - discovery.type=single-node
      - node.master=true
      - node.data=true
    depends_on:
      - kafka-connect-datagen

  kibana:
    image: kibana:7.8.1
    container_name: kibana
    hostname: kibana
    ports:
      - 5601:5601
    environment:
      - xpack.security.enabled=true
      - server.host=0.0.0.0
      - xpack.reporting.kibanaServer.hostname=0.0.0.0
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

  metricbeat:
    image: docker.elastic.co/beats/metricbeat:7.8.1
    container_name: metricbeat
    hostname: metricbeat
    user: root
    volumes:
      - ./elastic/metricbeat/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml

      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /sys/fs/cgroup/:/hostfs/sys/fs/cgroup:ro
      - /proc/:/hostfs/proc/:ro
      - /:/hostfs:ro
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - KIBANA_HOST=kibana:5601
    depends_on:
      - kibana

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.8.1
    container_name: filebeat
    hostname: filebeat
    user: root
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /sys/fs/cgroup/:/hostfs/sys/fs/cgroup:ro
      - /proc/:/hostfs/proc/:ro
      - /:/hostfs:ro
    environment:
      - setup.kibana.host=kibana:5601
      - output.elasticsearch.hosts=["elasticsearch:9200"]  
    depends_on:
      - kibana

  logstash:
    # https://www.elastic.co/guide/en/logstash/current/config-setting-files.html
    image: logstash:7.8.1
    hostname: logstash
    container_name: logstash
    ports:
      - 9600:9600
    volumes:
      - ./elastic/logstash:/usr/share/logstash/pipeline
    environment:
      - http.host=0.0.0.0
      - LOG_LEVEL=debug
    depends_on:
      - elasticsearch
  

      https://www.sarulabs.com/post/5/2019-08-12/sending-docker-logs-to-elasticsearch-and-kibana-with-filebeat.html